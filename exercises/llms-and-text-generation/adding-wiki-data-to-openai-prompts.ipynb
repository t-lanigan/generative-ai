{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86da1ad2",
   "metadata": {},
   "source": [
    "# The problem\n",
    "Open AI was only trained on data before 2021. Therefore it wont answer questions related to 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7906568a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4011316",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = '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'\n",
    "MODEL_NAME = 'gpt-3.5-turbo-instruct'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e8644d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"When did Russia invade Ukraine?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f37f65ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "ukraine_prompt = f\"\"\"\n",
    "Question: {question}\n",
    "Answer: \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a42d703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# openai.Completion.create(model=MODEL_NAME)\n",
    "\n",
    "ukraine_answer = openai.Completion.create(\n",
    "    model=MODEL_NAME,\n",
    "    prompt=ukraine_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ab8e31a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Russia invaded Ukraine on February 20, 2014, when Russian forces seized'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ukraine_answer[\"choices\"][0][\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c845a17",
   "metadata": {},
   "source": [
    "This is incorrect. Lets use same data scraped from wikipedia and prompt engineering to make it better"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72084745",
   "metadata": {},
   "source": [
    "### STEP 1 - Loading the Data with `pandas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d37271b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Get the Wikipedia page for \"2022\" since OpenAI's models stop in 2021\n",
    "params = {\n",
    "    \"action\": \"query\", \n",
    "    \"prop\": \"extracts\",\n",
    "    \"exlimit\": 1,\n",
    "    \"titles\": \"2022\",\n",
    "    \"explaintext\": 1,\n",
    "    \"formatversion\": 2,\n",
    "    \"format\": \"json\"\n",
    "}\n",
    "resp = requests.get(\"https://en.wikipedia.org/w/api.php\", params=params)\n",
    "response_dict = resp.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64384ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df[\"text\"] = response_dict[\"query\"][\"pages\"][0][\"extract\"].split(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62731c74",
   "metadata": {},
   "source": [
    "clean up the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8ba4f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.parser import parse\n",
    "\n",
    "# Clean up text to remove empty lines and headings\n",
    "df = df[(df[\"text\"].str.len() > 0) & (~df[\"text\"].str.startswith(\"==\"))]\n",
    "\n",
    "# In some cases dates are used as headings instead of being part of the\n",
    "# text sample; adjust so dated text samples start with dates\n",
    "prefix = \"\"\n",
    "for (i, row) in df.iterrows():\n",
    "    # If the row already has \" - \", it already has the needed date prefix\n",
    "    if \" – \" not in row[\"text\"]:\n",
    "        try:\n",
    "            # If the row's text is a date, set it as the new prefix\n",
    "            parse(row[\"text\"])\n",
    "            prefix = row[\"text\"]\n",
    "        except:\n",
    "            # If the row's text isn't a date, add the prefix\n",
    "            row[\"text\"] = prefix + \" – \" + row[\"text\"]\n",
    "df = df[df[\"text\"].str.contains(\" – \")].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eff2773",
   "metadata": {},
   "source": [
    "### Creating an Embeddings Index with `openai.Embedding`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3c6f74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_MODEL_NAME = \"text-embedding-ada-002\"\n",
    "batch_size = 100\n",
    "embeddings = []\n",
    "for i in range(0, len(df), batch_size):\n",
    "    # Send text data to OpenAI model to get embeddings\n",
    "    response = openai.Embedding.create(\n",
    "        input=df.iloc[i:i+batch_size][\"text\"].tolist(),\n",
    "        engine=EMBEDDING_MODEL_NAME\n",
    "    )\n",
    "\n",
    "    # Add embeddings to list\n",
    "    embeddings.extend([data[\"embedding\"] for data in response[\"data\"]])\n",
    "\n",
    "# Add embeddings list to dataframe\n",
    "df[\"embeddings\"] = embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386b0582",
   "metadata": {},
   "source": [
    "Save for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72b7f51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"embeddings.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7b7331",
   "metadata": {},
   "source": [
    "## Step 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2152dad6",
   "metadata": {},
   "source": [
    "### Finding Relevant Data with Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8dbd7bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.embeddings_utils import get_embedding, distances_from_embeddings\n",
    "\n",
    "def get_rows_sorted_by_relevance(question, df):\n",
    "    \"\"\"\n",
    "    Function that takes in a question string and a dataframe containing\n",
    "    rows of text and associated embeddings, and returns that dataframe\n",
    "    sorted from least to most relevant for that question\n",
    "    \"\"\"\n",
    "\n",
    "    # Get embeddings for the question text\n",
    "    question_embeddings = get_embedding(question, engine=EMBEDDING_MODEL_NAME)\n",
    "\n",
    "    # Make a copy of the dataframe and add a \"distances\" column containing\n",
    "    # the cosine distances between each row's embeddings and the\n",
    "    # embeddings of the question\n",
    "    df_copy = df.copy()\n",
    "    df_copy[\"distances\"] = distances_from_embeddings(\n",
    "        question_embeddings,\n",
    "        df_copy[\"embeddings\"].values,\n",
    "        distance_metric=\"cosine\"\n",
    "    )\n",
    "\n",
    "    # Sort the copied dataframe by the distances and return it\n",
    "    # (shorter distance = more relevant so we sort in ascending order)\n",
    "    df_copy.sort_values(\"distances\", ascending=True, inplace=True)\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "581fc320",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_rows_sorted_by_relevance(question, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bec62d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('embeddings.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699486f6",
   "metadata": {},
   "source": [
    "## Step 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65d6d19",
   "metadata": {},
   "source": [
    "### Composing a Custom Text Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c9c35486",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "def create_prompt(question, df, max_token_count):\n",
    "    \"\"\"\n",
    "    Given a question and a dataframe containing rows of text and their\n",
    "    embeddings, return a text prompt to send to a Completion model\n",
    "    \"\"\"\n",
    "    # Create a tokenizer that is designed to align with our embeddings\n",
    "    tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "    # Count the number of tokens in the prompt template and question\n",
    "    prompt_template = \"\"\"\n",
    "Answer the question based on the context below, and if the question\n",
    "can't be answered based on the context, say \"I don't know\"\n",
    "\n",
    "Context: \n",
    "\n",
    "{}\n",
    "\n",
    "---\n",
    "\n",
    "Question: {}\n",
    "Answer:\"\"\"\n",
    "\n",
    "    current_token_count = len(tokenizer.encode(prompt_template)) + \\\n",
    "                            len(tokenizer.encode(question))\n",
    "\n",
    "    context = []\n",
    "    for text in get_rows_sorted_by_relevance(question, df)[\"text\"].values:\n",
    "\n",
    "        # Increase the counter based on the number of tokens in this row\n",
    "        text_token_count = len(tokenizer.encode(text))\n",
    "        current_token_count += text_token_count\n",
    "\n",
    "        # Add the row of text to the list if we haven't exceeded the max\n",
    "        if current_token_count <= max_token_count:\n",
    "            context.append(text)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return prompt_template.format(\"\\n\\n###\\n\\n\".join(context), question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d86f7502",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = create_prompt(question, df, max_token_count=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b8f5dd",
   "metadata": {},
   "source": [
    "## Step 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495a549a",
   "metadata": {},
   "source": [
    "### Getting a Custom Q&A Response with `openai.Completion`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3913334c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(\n",
    "    question, df, max_prompt_tokens=1800, max_answer_tokens=150\n",
    "):\n",
    "    \"\"\"\n",
    "    Given a question, a dataframe containing rows of text, and a maximum\n",
    "    number of desired tokens in the prompt and response, return the\n",
    "    answer to the question according to an OpenAI Completion model\n",
    "\n",
    "    If the model produces an error, return an empty string\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = create_prompt(question, df, max_prompt_tokens)\n",
    "\n",
    "    try:\n",
    "        response = openai.Completion.create(\n",
    "            model=MODEL_NAME,\n",
    "            prompt=prompt,\n",
    "            max_tokens=max_answer_tokens\n",
    "        )\n",
    "        return response[\"choices\"][0][\"text\"].strip()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "626eb389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Russian invasion of Ukraine began on February 24, 2022.'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_question(question, df, max_prompt_tokens=1800, max_answer_tokens=150)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
